{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to RDataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ROOT RDataFrame\n",
    "\n",
    "[RDataFrame documentation](https://root.cern/doc/master/classROOT_1_1RDataFrame.html)\n",
    "\n",
    "- RDF is ROOT's high-level analysis interface. \n",
    "\n",
    "- Users define their analysis as a sequence of operations to be performed on the data-frame object; \n",
    "\n",
    "    - the framework takes care of the management of the loop over entries as well as low-level details such as I/O and parallelisation.\n",
    "\n",
    "- RDataFrame provides methods to perform most common operations required by ROOT analyses: \n",
    "\n",
    "    - at the same time, users can just as easily specify custom code that will be executed in the event loop.\n",
    "<img src=\"../images/rdf_1.png\" style=\"width: 75%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chapter 1: Basics of HEP data analysis with RDataFrame\n",
    "RDataFrame allows reading and writing trees, aiming at making HEP analysis easy to write and fast to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "treename = \"dataset\"\n",
    "filename = \"../data/example_file.root\"\n",
    "df = ROOT.RDataFrame(treename, filename)\n",
    "\n",
    "print(f\"Columns in the dataset: {df.GetColumnNames()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can `Define` new quantities, `Filter` rows based on custom expressions and retrieve some data aggregations such as a `Count` and a `Mean`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def1 = df.Define(\"c\", \"a+b\")\n",
    "\n",
    "fil1 = def1.Filter(\"c < 0.5\")\n",
    "\n",
    "count = fil1.Count()\n",
    "mean = fil1.Mean(\"c\")\n",
    "display = fil1.Display([\"a\",\"b\",\"c\"])\n",
    "\n",
    "print(f\"Number of rows after filter: {count.GetValue()}\")\n",
    "print(f\"Mean of column c after filter: {mean.GetValue()}\")\n",
    "print(\"Dataset contents:\")\n",
    "display.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Histograms with RDataFrame\n",
    "RDataFrame helps you streamline the creation and filling of histogram objects from your data. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "c = ROOT.TCanvas()\n",
    "h = df.Histo1D(\"vec1\")\n",
    "h.Draw()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `Histo1D` will create a one-dimensional histogram holding `double` values. \n",
    "\n",
    "- `Histo{2,3}D` do the same in higher dimensions. \n",
    "\n",
    "- These operations also accept a tuple with the same arguments that would be passed to the equivalent histogram object constructors. \n",
    "\n",
    "- For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "histo_name = \"histo_name\"\n",
    "histo_title = \"histo_title\"\n",
    "nbinsx = 100\n",
    "xlow = -10\n",
    "xup = 10\n",
    "\n",
    "# The traditional TH1D constructor\n",
    "# ROOT.TH1D(histo_name, histo_title, nbinsx, xlow, xup)\n",
    "\n",
    "# With RDataFrame\n",
    "c = ROOT.TCanvas()\n",
    "h = df.Histo1D((histo_name, histo_title, nbinsx, xlow, xup), \"vec1\")\n",
    "h.Draw()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Think about data-flow\n",
    "RDataFrame is built with a modular and flexible workflow in mind, summarised as follows:\n",
    "\n",
    "* build a data-frame object by specifying your data-set\n",
    "* apply a series of transformations to your data\n",
    "  * filter (e.g. apply some cuts) or\n",
    "  * define a new column (e.g. the result of an expensive computation on columns)\n",
    "* apply actions to the transformed data to produce results (e.g. fill a histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Important Note!\n",
    "Make sure to **book all transformations and actions before** you access the contents of any of the results: this lets RDataFrame accumulate work and then produce all results at the same time, upon first access to any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_wrong = ROOT.RDataFrame(treename, filename)\n",
    "\n",
    "h_a = df_wrong.Histo1D(\"a\")\n",
    "h_a_val = h_a.GetValue()\n",
    "\n",
    "h_b = df_wrong.Histo1D(\"b\")\n",
    "h_b_val = h_b.GetValue()\n",
    "\n",
    "h_vec1 = df_wrong.Histo1D(\"vec1\")\n",
    "h_vec1_val = h_vec1.GetValue()\n",
    "\n",
    "print(f\"The dataset was processed {df_wrong.GetNRuns()} times.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_good = ROOT.RDataFrame(treename, filename)\n",
    "\n",
    "h_a = df_good.Histo1D(\"a\")\n",
    "h_b = df_good.Histo1D(\"b\")\n",
    "h_vec1 = df_good.Histo1D(\"vec1\")\n",
    "\n",
    "h_a_val = h_a.GetValue()\n",
    "h_b_val = h_b.GetValue()\n",
    "h_vec1_val = h_vec1.GetValue()\n",
    "\n",
    "print(f\"The dataset was processed {df_good.GetNRuns()} time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Operation categories in RDataFrame\n",
    "There are 3 main types of operations you can perform on RDataFrames:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Transformations**: manipulate the dataset, return a modified RDataFrame for further processing.\n",
    "\n",
    "| Transformation    | Description                                                |\n",
    "|-------------------|------------------------------------------------------------|\n",
    "| Alias()           | Introduce an alias for a particular column name.           |\n",
    "| Define()          | Creates  a new column in the dataset.                      |\n",
    "| Filter()          | Filter rows based on user-defined conditions.              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Actions**: aggregate (parts of) the dataset into a result.\n",
    "\n",
    "| Action                        | Description                                                                          |\n",
    "|------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| Count()                            | Return the number of events processed.                                               |\n",
    "| Display()                          | Provides a printable object representing the dataset contents.                       |\n",
    "| Graph()                            | Fills a TGraph  with the two columns provided.                                       |\n",
    "| Histo1D(), Histo2D(), Histo3D()    | Fill a one-, two-, three-dimensional histogram with the processed column values.     |\n",
    "| Max(), Min()                       | Return the maximum(minimum) of processed column values.                              |\n",
    "| Snapshot()        | Writes processed data-set to a new TTree.              |\n",
    "| ...                                | ...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Queries**: these methods  query information about your dataset and the RDataFrame status.\n",
    "\n",
    "| Operation           | Description                                                                              |\n",
    "|---------------------|------------------------------------------------------------------------------------------|\n",
    "| GetColumnNames()    | Get the names of all the available columns of the dataset.                               |\n",
    "| GetColumnType()     | Return the type of a given column as a string.                                           |\n",
    "| SaveGraph()         | Export the computation graph of an RDataFrame in graphviz format for easy inspection.     |\n",
    "| ...                 | ...                                                                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the full list, visit [RDataFrame documentation page](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#cheatsheet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with `numpy` arrays\n",
    "- RDataFrame offers interoperability with `numpy` arrays. \n",
    "\n",
    "- It can be created from a dictionary of such arrays and it can also export its contents to the same format. \n",
    "\n",
    "- All operations are available also when using the `numpy`-based dataset.\n",
    "\n",
    "- **Note:** this support is limited to one-dimensional numpy arrays, which are directly mapped to columns in the RDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "np_dict = {colname: numpy.random.rand(100) for colname in [\"a\",\"b\",\"c\"]}\n",
    "\n",
    "df = ROOT.RDF.FromNumpy(np_dict)\n",
    "\n",
    "print(f\"Columns in the RDataFrame: {df.GetColumnNames()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = df.Count()\n",
    "m_a = df.Mean(\"a\")\n",
    "\n",
    "fil1 = df.Filter(\"c < 0.7\")\n",
    "def1 = fil1.Define(\"d\", \"a+b+c\")\n",
    "h = def1.Histo1D(\"d\")\n",
    "\n",
    "c = ROOT.TCanvas()\n",
    "h.Draw()\n",
    "\n",
    "print(f\"Number of rows in the dataset: {co.GetValue()}\")\n",
    "print(f\"Average value of column a: {m_a.GetValue()}\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collections and object selections\n",
    "\n",
    "- RDataFrame reads collections as the special type [ROOT::RVec](https://root.cern/doc/master/classROOT_1_1VecOps_1_1RVec.html) - e.g. a branch containing an array of floating point numbers can be read as a `ROOT::RVec<float>`.\n",
    "\n",
    "- C-style arrays (with variable or static size), `std::vectors` and many other collection types can be read this way. \n",
    "\n",
    "- When reading ROOT data, column values of type `ROOT::RVec<T>` perform no copy of the underlying array.\n",
    "\n",
    "- `RVec` is a container similar to `std::vector` (and can be used just like a `std::vector`) but it also offers a rich interface to operate on the array elements in a vectorised fashion, similarly to Python's NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b99067",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "treename = \"myDataset\"\n",
    "filename = \"../data/collections_dataset.root\"\n",
    "df = ROOT.RDataFrame(treename, filename)\n",
    "\n",
    "print(f\"Columns in the dataset: {df.GetColumnNames()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3633ae",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To quickly inspect the data we can export it as a dictionary of `numpy` arrays thanks to the `AsNumpy` RDataFrame method. \n",
    "\n",
    "Note that for each row, `E` is an array of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4664f42",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "npy_dict = df.AsNumpy([\"E\"])\n",
    "\n",
    "for row, vec in enumerate(npy_dict[\"E\"]):\n",
    "    print(f\"\\nRow {row} contains:\\n{vec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896f202",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Define a new column with operations on RVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f140a78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.Define(\"good_pt\", \"sqrt(px*px + py*py)[E>100]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca3b396",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`sqrt(px*px + py*py)[E>100]`:\n",
    "- `px`, `py` and `E` are the columns, the elements of those columns are `RVec`s\n",
    "\n",
    "- Operations on `RVec`s, such as sum, product, sqrt, preserve the dimensionality of the array\n",
    "\n",
    "- `[E>100]` selects the elements of the array that satisfy the condition\n",
    "\n",
    "- `E > 100`: boolean expressions on `RVec`s such as `E > 100` return a mask, that is an array with information which values pass the selection (e.g. `[0, 1, 0, 0]` if only the second element satisfies the condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e283340e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now we can plot the newly defined column values in a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795d4a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "c = ROOT.TCanvas()\n",
    "h = df1.Histo1D((\"pt\", \"pt\", 16, 0, 4), \"good_pt\")\n",
    "h.Draw()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: What about the results? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd70edc7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Snapshot - save datasets to a ROOT file after processing\n",
    "With RDataFrame, you can read your dataset, add new columns with processed values and finally use `Snapshot` to save the resulting data to a ROOT file in TTree format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c56f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = ROOT.RDataFrame(\"dataset\",\"../data/example_file.root\")\n",
    "df1 = df.Define(\"c\",\"a+b\")\n",
    "\n",
    "out_treename = \"outtree\"\n",
    "out_filename = \"outtree.root\"\n",
    "out_columns = [\"a\",\"b\",\"c\"]\n",
    "snapdf = df1.Snapshot(out_treename, out_filename, out_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaaed15",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can now check that the dataset was correctly stored in a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9de7b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rootls -lt outtree.root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7bc7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Result of a Snapshot is still an RDataFrame that can be further used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f46a0b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "snapdf.Display().Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98928de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cutflow reports\n",
    "Filters applied to the dataset can be given a name. The `Report` method will gather information about filter efficiency and show the data flow between subsequent cuts on the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7610f52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = ROOT.RDataFrame(\"sig_tree\", \"https://root.cern/files/Higgs_data.root\")\n",
    "\n",
    "filter1 = df.Filter(\"lepton_eta > 0\", \"Lepton eta cut\")\n",
    "filter2 = filter1.Filter(\"lepton_phi < 1\", \"Lepton phi cut\")\n",
    "\n",
    "rep = df.Report()\n",
    "rep.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: More advance features - what else would we need in a real analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDatsetSpec and FromSpec\n",
    "\n",
    "What if you have many different samples - multiple tree or rntuple names and many different file names with some metadata information as well? \n",
    "- We have the RDatasetSpec class for that!\n",
    "- And especially, get familiar with the `FromSpec` method thanks to which you can create a single dataframe consisting of many different samples which are added via a JSON file.\n",
    "\n",
    "Example:\n",
    "```json\n",
    "{\n",
    "   \"samples\": {\n",
    "      \"sampleA\": {\n",
    "         \"trees\": [\"tree1\", \"tree2\"],\n",
    "         \"files\": [\"file1.root\", \"file2.root\"],\n",
    "         \"metadata\": {\"lumi\": 1.0, }\n",
    "      },\n",
    "      \"sampleB\": {\n",
    "         \"trees\": [\"tree3\", \"tree4\"],\n",
    "         \"files\": [\"file3.root\", \"file4.root\"],\n",
    "         \"metadata\": {\"lumi\": 0.5, }\n",
    "      },\n",
    "      ...\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ROOT.RDF.Experimental.FromSpec(\"../data/dataset_spec.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now simply continue your analysis as per usual... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if some operations are valid only for some of the samples? \n",
    "- Solution: use `DefinePerSample` method - the samples can be recognized thanks to one or more metadata instances and then we can make use of `RSampleInfo` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.DefinePerSample(\"xsecs\", 'rdfsampleinfo_.GetD(\"xsecs\")') \n",
    "# This is a teaser - how this can be used further is shown in the last chapter of this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including systematic variations in your analysis\n",
    "\n",
    "At some point in the development of a HEP data analysis workflow, the treatment of systematic variations in the observed quantities will become necessary. From the standpoint of a HEP physicist, the study of systematic variations involves many different, often conceptually complex cases. From the standpoint of the pure numerical computation, however, what typically happens is that the application must produce multiple results instead of a single one, each computed in a \"universe\" in which certain inputs take modified values.\n",
    "\n",
    "In the next few cells, we explore the RDataFrame API devoted to helping the user include systematic variations in their analysis code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treename = \"myDataset\"\n",
    "filename = \"../data/collections_dataset.root\"\n",
    "df = ROOT.RDataFrame(treename, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering variations for one observable\n",
    "\n",
    "As a basic example, let's see how to include two variations for the column `px`, including giving them special labels. Note that in the call to `Vary` we can use values from columns available in the dataset, including the column we are currently registering variations for. In this example, we are booking the nominal histogram via the usual `Histo1D` method.\n",
    "\n",
    "Note the following in the example:\n",
    "\n",
    "* Custom names for variations can be passed in a list via the `variationTags` parameter.\n",
    "* The name of the input column is used as the default name for the variation, unless the `variationName` parameter is used as in this example.\n",
    "* The full variation name will be composed of the varied column name and the variation tags (e.g. \"mypt:down\", \"mypt:up\" in this example).\n",
    "* The histogram is filled with values of the `good_pt` column, defined after the `Vary` call. The presence of systematic variations for certain columns is automatically propagated through filters, defines and actions, and RDataFrame will take these dependencies into account when producing varied results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.Define(\"pt\", \"sqrt(px*px + py*py)\")\n",
    "\n",
    "nominal_histo = (\n",
    "    df.Vary(\n",
    "        colName=\"pt\",\n",
    "        expression=\"ROOT::RVec<ROOT::RVecD>{pt*0.95, pt*1.05}\",\n",
    "        variationTags=[\"down\", \"up\"],\n",
    "        variationName=\"mypt\")\n",
    "      .Define(\"good_pt\", \"pt[E>100]\")\n",
    "      .Histo1D(\"good_pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to retrieve also all the varied histograms, we pass the pointer to the action just booked to the `VariationsFor` function, as shown below. This will return a dictionary containing the nominal histogram as well as all the varied histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_histos = ROOT.RDF.Experimental.VariationsFor(nominal_histo)\n",
    "\n",
    "c = ROOT.TCanvas()\n",
    "\n",
    "all_histos[\"nominal\"].SetLineColor(ROOT.kBlue)\n",
    "all_histos[\"nominal\"].Draw()\n",
    "\n",
    "all_histos[\"mypt:down\"].SetLineColor(ROOT.kRed)\n",
    "all_histos[\"mypt:down\"].Draw(\"SAME\")\n",
    "\n",
    "all_histos[\"mypt:up\"].SetLineColor(ROOT.kGreen)\n",
    "all_histos[\"mypt:up\"].Draw(\"SAME\")\n",
    "\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra - registering variations for multiple columns simultaneously\n",
    "\n",
    "The `Vary` function also allows to vary multiple columns simultaneously (in \"lockstep\"). The expression in this case must return an RVec of RVecs, one per column: each inner vector contains the varied values for one column, and the inner vectors follow the same ordering as the column names passed as first argument. Besides the variation tags, in this case we also have to explicitly pass a variation name as there is no one column name that can be used as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ROOT.RDataFrame(treename, filename)\n",
    "\n",
    "nominal_histo_lockstep = (\n",
    "    df.Vary(\n",
    "        colNames=[\"px\", \"py\"],\n",
    "        expression=\"ROOT::RVec<ROOT::RVec<ROOT::RVecD>>{{px*0.95, px*1.05}, {py*0.95, py*1.05}}\",\n",
    "        variationTags=[\"down\", \"up\"],\n",
    "        variationName=\"pxAndpy\")\n",
    "      .Define(\"pt_lockstep\", \"sqrt(px*px + py*py)[E>100]\")\n",
    "      .Histo1D(\"pt_lockstep\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_histos = ROOT.RDF.Experimental.VariationsFor(nominal_histo_lockstep)\n",
    "\n",
    "c = ROOT.TCanvas()\n",
    "\n",
    "all_histos[\"nominal\"].SetLineColor(ROOT.kBlue)\n",
    "all_histos[\"nominal\"].Draw()\n",
    "\n",
    "all_histos[\"pxAndpy:down\"].SetLineColor(ROOT.kRed)\n",
    "all_histos[\"pxAndpy:down\"].Draw(\"SAME\")\n",
    "\n",
    "all_histos[\"pxAndpy:up\"].SetLineColor(ROOT.kGreen)\n",
    "all_histos[\"pxAndpy:up\"].Draw(\"SAME\")\n",
    "\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be5b9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using C++ functions in Python\n",
    "- We still want to perform complex operations in Python but plain Python code is prone to be slow and not thread-safe. \n",
    "\n",
    "- Instead, you can inject C++ functions that will do the work in your event loop during runtime. \n",
    "\n",
    "- This mechanism uses the C++ interpreter `cling` shipped with ROOT, making this possible in a single line of code. \n",
    "\n",
    "- Let's start by defining a function that will allow us to change the type of a the RDataFrame dataset entry numbers (stored in the special column \"rdfentry\") from `unsigned long long` to `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1bcee4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cpp\n",
    "\n",
    "float asfloat(unsigned long long entrynumber){\n",
    "    return entrynumber;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f4bd1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then let's define another function that takes a `float` values and computes its square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a8b4f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cpp\n",
    "\n",
    "float square(float val){\n",
    "    return val * val;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90522e44",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And now let's use these functions with RDataFrame! \n",
    "\n",
    "We start by creating an empty RDataFrame with 100 consecutive entries and defining new columns on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd70d3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new RDataFrame from scratch with 100 consecutive entries\n",
    "df = ROOT.RDataFrame(100)\n",
    "\n",
    "# Create a new column using the previously declared C++ functions\n",
    "df1 = df.Define(\"a\", \"asfloat(rdfentry_)\")\n",
    "df2 = df1.Define(\"b\", \"square(a)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1005d7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can now plot the values of the columns in a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a35cd0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Show the two columns created in a graph\n",
    "c = ROOT.TCanvas()\n",
    "graph = df2.Graph(\"a\",\"b\")\n",
    "graph.SetMarkerStyle(20)\n",
    "graph.SetMarkerSize(0.5)\n",
    "graph.SetMarkerColor(ROOT.kBlue)\n",
    "graph.SetTitle(\"My graph\")\n",
    "graph.Draw(\"AP\")\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Scaling up your analysis - multi-threading and distributed RDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ae85d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using all cores of your machine with multi-threaded RDataFrame\n",
    "- RDataFrame can transparently perform multi-threaded event loops to speed up the execution of its actions. \n",
    "\n",
    "- Users have to call `ROOT::EnableImplicitMT()` before constructing the RDataFrame object to indicate that it should take advantage of a pool of worker threads. \n",
    "\n",
    "- Each worker thread processes a distinct subset of entries, and their partial results are merged before returning the final values to the user.\n",
    "\n",
    "- RDataFrame operations such as Histo1D or Snapshot are guaranteed to work correctly in multi-thread event loops. \n",
    "\n",
    "- User-defined expressions, such as strings or lambdas passed to `Filter`, `Define`, `Foreach`, `Reduce` or `Aggregate` will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4528b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Activate multithreading capabilities\n",
    "# By default takes all available cores on the machine\n",
    "ROOT.EnableImplicitMT()\n",
    "\n",
    "# treename = \"Events\"\n",
    "# filename = \"root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root\"\n",
    "# df = ROOT.RDataFrame(treename, filename)\n",
    "\n",
    "# df.Sum(\"nMuon\").GetValue()\n",
    "\n",
    "# Disable implicit multithreading when done\n",
    "ROOT.DisableImplicitMT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbd633",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple concurrent RDataFrame runs\n",
    "If your analysis needs multiple RDataFrames to run (for example multiple dataset samples, data vs simulation etc.), make use of `ROOT.RDF.RunGraphs` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f342906a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ROOT.EnableImplicitMT()\n",
    "treename1 = \"myDataset\"\n",
    "filename1 = \"../data/collections_dataset.root\"\n",
    "treename2 = \"dataset\"\n",
    "filename2 = \"../data/example_file.root\"\n",
    "\n",
    "df1 = ROOT.RDataFrame(treename1, filename1)\n",
    "df2 = ROOT.RDataFrame(treename2, filename2)\n",
    "h1 = df1.Histo1D(\"px\")\n",
    "h2 = df2.Histo1D(\"a\")\n",
    "\n",
    "\n",
    "ROOT.RDF.RunGraphs((h1, h2))\n",
    "ROOT.DisableImplicitMT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b715694",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "c = ROOT.TCanvas()\n",
    "h1.Draw()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a5420",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "c = ROOT.TCanvas()\n",
    "h2.Draw()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc296f7d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributed RDataFrame\n",
    "\n",
    "An `RDataFrame` analysis written in Python can be executed both *locally* - possibly in parallel on the cores of the machine - and *distributedly* by offloading computations to external resources, which include:\n",
    "\n",
    "- [Spark](https://spark.apache.org/) and \n",
    "- [Dask](https://dask.org/) clusters. \n",
    "\n",
    "- This feature is enabled by the architecture depicted below.\n",
    "\n",
    "- It shows that RDataFrame computation graphs can be mapped to different kinds of resources via backends.\n",
    "\n",
    "- In this notebook we will exercise the Dask backend, which divides an `RDataFrame` input dataset in logical ranges and submits computations for each of those ranges to Dask resources.\n",
    "\n",
    "<img src=\"../images/DistRDF_architecture.png\" alt=\"Distributed RDataFrame\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2731e8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create a Dask client\n",
    "\n",
    "- In order to work with a Dask cluster we need a `Client` object.\n",
    "- It represents the connection to that cluster and allows to configure execution-related parameters (e.g. number of cores, memory). \n",
    "- The client object is just the intermediary between our client session and the cluster resources, \n",
    "- Dask supports many different resource managers.\n",
    "- We will follow the [Dask documentation](https://distributed.dask.org/en/stable/client.html) regarding the creation of a `Client`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e156e5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers=2, threads_per_worker=1, processes=True, memory_limit=\"2GiB\")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ffed1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create a ROOT dataframe\n",
    "\n",
    "We now create an RDataFrame based on the same dataset seen in the exercise [rdataframe-dimuon](exercises/rdataframe-dimuon.ipynb).\n",
    "\n",
    "A Dask `RDataFrame` receives two extra parameters: \n",
    "- the executor, which in this case will be the dask client object\n",
    "- the number of partitions to apply to the dataset (npartitions)\n",
    "\n",
    "Besides this detail, a Dask `RDataFrame` is not different from a local `RDataFrame`: the analysis presented in this notebook would not change if we wanted to execute it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405cf12f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use a Dask RDataFrame\n",
    "df = ROOT.RDataFrame(\"h42\",\n",
    "                \"https://root.cern/files/h1big.root\",\n",
    "                executor=client,\n",
    "                npartitions=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563a28e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run your analysis unchanged\n",
    "\n",
    "- From now on, the rest of your application can be written **exactly** as we have seen with local RDataFrame. \n",
    "\n",
    "- The goal of the distributed RDataFrame module is to support all the traditional RDataFrame operations (those that make sense in a distributed context at least). \n",
    "\n",
    "- The list of operations that are currently available in distributed mode and can be found in the corresponding [section of the documentation](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#rdf_distrdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Chapter: The Higgs to four lepton analysis from the ATLAS Open Data release of 2020, with RDataFrame\n",
    "\n",
    "We have briefly discussed most of what is needed to follow this analysis - try it yourself and discover the Higgs boson!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This exercise is the Higgs to four lepton analysis from the ATLAS Open Data release in 2020 (http://opendata.atlas.cern/release/2020/documentation/). The data was taken with the ATLAS detector during 2016 at a center-of-mass energy of 13 TeV. The decay of the Standard Model Higgs boson to two Z bosons and subsequently to four leptons is called the \"golden channel\". The selection leads to a narrow invariant mass peak on top a relatively smooth and small background, revealing the Higgs at 125 GeV. Systematic errors for the MC scale factors are computed and the Vary function of RDataFrame is used for plotting. The analysis is translated to an RDataFrame workflow processing about 300 MB of simulated events and data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the input dataset\n",
    "\n",
    "In this exercise, we use a JSON config file to define the dataset specification. It contains the names of the files, together with metadata associated with different samples. The metadata contained in the JSON file is accessible within a [`DefinePerSample`](https://root.cern/doc/v628/classROOT_1_1RDF_1_1RInterface.html#a29d77593e95c0f84e359a802e6836a0e) call, through the [`RSampleInfo`](https://root.cern/doc/master/classROOT_1_1RDF_1_1RSampleInfo.html) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The analysis needs custom code written in a separate header, so we include it here\n",
    "ROOT.gInterpreter.Declare('#include \"utils.h\"')\n",
    "\n",
    "dataset_spec = \"../data/dataset_spec.json\"\n",
    "df = ROOT.RDF.Experimental.FromSpec(dataset_spec)  # Creates a single dataframe for all the samples\n",
    "\n",
    "df = df.DefinePerSample(\"xsecs\", 'rdfsampleinfo_.GetD(\"xsecs\")')\n",
    "df = df.DefinePerSample(\"lumi\", 'rdfsampleinfo_.GetD(\"lumi\")')\n",
    "df = df.DefinePerSample(\"sumws\", 'rdfsampleinfo_.GetD(\"sumws\")')\n",
    "df = df.DefinePerSample(\"sample_category\", 'rdfsampleinfo_.GetS(\"sample_category\")')\n",
    "df = df.DefinePerSample(\"scale\", \"scale(rdfslot_, rdfsampleinfo_)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform selections\n",
    "\n",
    "We need to select events with exactly four good leptons conserving charge and lepton numbers. Note that all collections read by RDataFrame are implicitly handled as the `ROOT::RVec` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select electron or muon trigger\n",
    "df = df.Filter(\"trigE || trigM\")\n",
    "\n",
    "# good_lep is the mask for the good leptons.\n",
    "# The lepton types are PDG numbers and set to 11 or 13 for an electron or muon\n",
    "# irrespective of the charge.\n",
    "\n",
    "df = (\n",
    "    df.Define(\n",
    "        \"good_lep\",\n",
    "        \"abs(lep_eta) < 2.5 && lep_pt > 5000 && lep_ptcone30 / lep_pt < 0.3 && lep_etcone20 / lep_pt < 0.3\",\n",
    "    )\n",
    "    .Filter(\"Sum(good_lep) == 4\")\n",
    "    .Filter(\"Sum(lep_charge[good_lep]) == 0\")\n",
    "    .Define(\"goodlep_sumtypes\", \"Sum(lep_type[good_lep])\")\n",
    "    .Filter(\"goodlep_sumtypes == 44 || goodlep_sumtypes == 52 || goodlep_sumtypes == 48\")\n",
    ")\n",
    "\n",
    "# Apply additional cuts depending on lepton flavour\n",
    "df = df.Filter(\n",
    "    \"GoodElectronsAndMuons(lep_type[good_lep], lep_pt[good_lep], lep_eta[good_lep], lep_phi[good_lep], lep_E[good_lep], lep_trackd0pvunbiased[good_lep], lep_tracksigd0pvunbiased[good_lep], lep_z0[good_lep])\"\n",
    ")\n",
    "\n",
    "# Create new columns with the kinematics of good leptons\n",
    "df = (\n",
    "    df.Define(\"goodlep_pt\", \"lep_pt[good_lep]\")\n",
    "    .Define(\"goodlep_eta\", \"lep_eta[good_lep]\")\n",
    "    .Define(\"goodlep_phi\", \"lep_phi[good_lep]\")\n",
    "    .Define(\"goodlep_E\", \"lep_E[good_lep]\")\n",
    "    .Define(\"goodlep_type\", \"lep_type[good_lep]\")\n",
    ")\n",
    "\n",
    "# Select leptons with high transverse momentum\n",
    "df = df.Filter(\"goodlep_pt[0] > 25000 && goodlep_pt[1] > 15000 && goodlep_pt[2] > 10000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the relevant observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reweighting of the samples is different for \"data\" and \"MC\".\n",
    "# Use DefinePerSample to define which samples are MC and hence need reweighting\n",
    "df = df.DefinePerSample(\"isMC\", 'rdfsampleinfo_.Contains(\"mc\")')\n",
    "df = df.Define(\n",
    "    \"weight\",\n",
    "    \"double x; return isMC ? weights(scaleFactor_ELE, scaleFactor_MUON, scaleFactor_LepTRIGGER, scaleFactor_PILEUP, scale, mcWeight, xsecs, sumws, lumi) :  1.;\",\n",
    ")\n",
    "\n",
    "df = df.Define(\"m4l\", \"ComputeInvariantMass(goodlep_pt, goodlep_eta, goodlep_phi, goodlep_E)\")\n",
    "\n",
    "# Book histograms for the four different samples: data, higgs, zz and other (this is specific to this particular analysis)\n",
    "histos = []\n",
    "for sample_category in [\"data\", \"higgs\", \"zz\", \"other\"]:\n",
    "    histos.append(\n",
    "        df.Filter(f'sample_category == \"{sample_category}\"').Histo1D(\n",
    "            ROOT.RDF.TH1DModel(f\"{sample_category}\", \"m4l\", 24, 80, 170),\n",
    "            \"m4l\",\n",
    "            \"weight\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate systematic uncertainties\n",
    "\n",
    "The systematic uncertainty in this analysis is the MC scale factor uncertainty that depends on lepton kinematics such as pT or pseudorapidity. Muons uncertainties are negligible, as stated in https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/MUON-2018-03/. Electrons uncertainties are evaluated based on the plots available in https://doi.org/10.48550/arXiv.1908.00005. The uncertainties are linearly interpolated, using the `TGraph::Eval()` method, to cover a range of pT values covered by the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one helper object to run the interpolation for the systematic uncertainty evaluation in the event loop\n",
    "ROOT.gInterpreter.ProcessLine(\"VaryHelper variationsFactory;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Vary method to add the systematic variations to the total MC scale factor (\"weight\") of the analysis.\n",
    "df_variations_mc = (\n",
    "    df.Filter(\"isMC == true\")\n",
    "    .Vary(\"weight\", \"variationsFactory(weight, goodlep_pt, goodlep_type)\", [\"up\", \"down\"])\n",
    "    .Histo1D(ROOT.RDF.TH1DModel(\"Invariant Mass\", \"m4l\", 24, 80, 170), \"m4l\", \"weight\")\n",
    ")\n",
    "histos_mc = ROOT.RDF.Experimental.VariationsFor(df_variations_mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving histograms and plotting\n",
    "\n",
    "We reached the end of the analysis part. We now evaluate the total MC uncertainty based on the variations. No computation graph was triggered yet, we trigger the computation graph for all histograms at once now, by calling 'histos_mc[\"nominal\"].GetXaxis()'. Note, in this case the uncertainties are symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, histos_mc[\"nominal\"].GetXaxis().GetNbins()):\n",
    "    (\n",
    "        histos_mc[\"nominal\"].SetBinError(\n",
    "            i, (histos_mc[\"weight:up\"].GetBinContent(i) - histos_mc[\"nominal\"].GetBinContent(i))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plot of the data, individual MC contributions and the total MC scale factor systematic variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.gROOT.SetStyle(\"ATLAS\")\n",
    "\n",
    "# Create canvas with pad\n",
    "c4 = ROOT.TCanvas(\"c4\", \"\", 620, 620)\n",
    "pad = ROOT.TPad(\"upper_pad\", \"\", 0, 0, 1, 1)\n",
    "pad.SetTickx(False)\n",
    "pad.SetTicky(False)\n",
    "pad.Draw()\n",
    "pad.cd()\n",
    "\n",
    "# Draw stack with MC contributions\n",
    "stack = ROOT.THStack()\n",
    "\n",
    "# Retrieve values of the data and MC histograms in order to plot them.\n",
    "# Draw cloned histograms to preserve graphics when original objects goes out of scope\n",
    "# Note: GetValue() action operation is performed after all lazy actions of the RDF were defined first.\n",
    "h_data = histos[0].GetValue().Clone()\n",
    "h_higgs = histos[1].GetValue().Clone()\n",
    "h_zz = histos[2].GetValue().Clone()\n",
    "h_other = histos[3].GetValue().Clone()\n",
    "\n",
    "for h, color in zip([h_other, h_zz, h_higgs], [ROOT.kViolet-9, ROOT.kAzure-9, ROOT.kRed+2]):\n",
    "    h.SetLineWidth(1)\n",
    "    h.SetLineColor(1)\n",
    "    h.SetFillColor(color)\n",
    "    stack.Add(h)\n",
    "\n",
    "stack.Draw(\"HIST\")\n",
    "stack.GetXaxis().SetLabelSize(0.04)\n",
    "stack.GetXaxis().SetTitleSize(0.045)\n",
    "stack.GetXaxis().SetTitleOffset(1.3)\n",
    "stack.GetXaxis().SetTitle(\"m_{4l}^{H#rightarrow ZZ} [GeV]\")\n",
    "stack.GetYaxis().SetLabelSize(0.04)\n",
    "stack.GetYaxis().SetTitleSize(0.045)\n",
    "stack.GetYaxis().SetTitle(\"Events\")\n",
    "stack.SetMaximum(35)\n",
    "stack.GetYaxis().ChangeLabel(1, -1, 0)\n",
    "\n",
    "# Draw MC scale factor and variations\n",
    "histos_mc[\"nominal\"].SetFillColor(ROOT.kBlack)\n",
    "histos_mc[\"nominal\"].SetFillStyle(3254)\n",
    "h_nominal = histos_mc[\"nominal\"].DrawClone(\"E2 same\")\n",
    "histos_mc[\"weight:up\"].SetLineColor(ROOT.kGreen+2)\n",
    "h_weight_up = histos_mc[\"weight:up\"].DrawClone(\"HIST SAME\")\n",
    "histos_mc[\"weight:down\"].SetLineColor(ROOT.kBlue+2)\n",
    "h_weight_down = histos_mc[\"weight:down\"].DrawClone(\"HIST SAME\")\n",
    "\n",
    "# Draw data histogram\n",
    "h_data.SetMarkerStyle(20)\n",
    "h_data.SetMarkerSize(1.2)\n",
    "h_data.SetLineWidth(2)\n",
    "h_data.SetLineColor(ROOT.kBlack)\n",
    "h_data.Draw(\"E SAME\")  # Draw raw data with errorbars\n",
    "\n",
    "# Add legend\n",
    "legend = ROOT.TLegend(0.57, 0.65, 0.94, 0.94)\n",
    "legend.SetTextFont(42)\n",
    "legend.SetFillStyle(0)\n",
    "legend.SetBorderSize(0)\n",
    "legend.SetTextSize(0.02)\n",
    "legend.SetTextAlign(32)\n",
    "legend.AddEntry(h_data, \"Data\", \"lep\")\n",
    "legend.AddEntry(h_higgs, \"Higgs MC\", \"f\")\n",
    "legend.AddEntry(h_zz, \"ZZ MC\", \"f\")\n",
    "legend.AddEntry(h_other, \"Other MC\", \"f\")\n",
    "legend.AddEntry(h_weight_down, \"Total MC Variations Down\", \"l\")\n",
    "legend.AddEntry(h_weight_up, \"Total MC Variations Up\", \"l\")\n",
    "legend.AddEntry(h_nominal, \"Total MC Uncertainty\", \"f\")\n",
    "legend.Draw()\n",
    "\n",
    "text = ROOT.TLatex()\n",
    "text.SetTextFont(72)\n",
    "text.SetTextSize(0.04)\n",
    "text.DrawLatexNDC(0.19, 0.85, \"ATLAS\")\n",
    "text.SetTextFont(42)\n",
    "text.DrawLatexNDC(0.19 + 0.15, 0.85, \"Open Data\")\n",
    "text.SetTextSize(0.035)\n",
    "text.DrawLatexNDC(0.21, 0.80, \"#sqrt{s} = 13 TeV, 10 fb^{-1}\")\n",
    "\n",
    "c4.Draw()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
